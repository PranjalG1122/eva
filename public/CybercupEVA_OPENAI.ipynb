{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tePJaLVb8EQc"
      },
      "outputs": [],
      "source": [
        "# @markdown connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lAEmIyBL3E60"
      },
      "outputs": [],
      "source": [
        "# @title Dependencies\n",
        "\n",
        "# !CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python --upgrade\n",
        "!pip install langchain --upgrade\n",
        "!pip install langchainhub --upgrade\n",
        "!pip install chromadb --upgrade\n",
        "# !pip install qdrant-client --upgrade\n",
        "!pip install openai --upgrade\n",
        "# !pip install python-dotenv --upgrade\n",
        "!pip install tiktoken  --upgrade\n",
        "!pip install Flask --upgrade\n",
        "!pip install flask-ngrok2 --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tHVQ3Pk3ZQpB"
      },
      "outputs": [],
      "source": [
        "#@title Install bore\n",
        "\n",
        "%cd /content\n",
        "\n",
        "!wget https://github.com/ekzhang/bore/releases/download/v0.4.0/bore-v0.4.0-x86_64-unknown-linux-musl.tar.gz -O bore.tar.gz\n",
        "!tar -xvf bore.tar.gz\n",
        "!rm bore.tar.gz\n",
        "!mv ./bore /usr/local/bin/bore\n",
        "!chmod +x /usr/local/bin/bore\n",
        "\n",
        "script = \"\"\"\n",
        "until bore local $1 --to bore.pub; do\n",
        "  echo \"bore tunnel crashed with exit code $?. Respawning..\" >&2\n",
        "  sleep 1\n",
        "done\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "with open('/content/bore.sh', 'w') as bore:\n",
        "    bore.write(script)\n",
        "\n",
        "!chmod +x ./bore.sh\n",
        "\n",
        "%cd /content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GTXUaPUF4EQN"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from langchain.chains import LLMChain, ConversationalRetrievalChain, RetrievalQA\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "from langchain.vectorstores import Chroma, Qdrant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lKrl-Te7KzwY"
      },
      "outputs": [],
      "source": [
        "# @title Set OpenAI API Key\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aDLn1Rea7fSI"
      },
      "outputs": [],
      "source": [
        "# @title Set Model\n",
        "\n",
        "model = \"gpt-3.5-turbo\" # @param [\"gpt-3.5-turbo\", \"gpt-4\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JGOpQfgzJpWS"
      },
      "outputs": [],
      "source": [
        "# @title Load Data\n",
        "\n",
        "loader = DirectoryLoader('/content/drive/MyDrive/CyberCup23H2/embed_src', glob='*.txt', loader_cls=TextLoader)\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=64, chunk_overlap=8)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "vectorstore = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "# vectorstore = Qdrant.from_documents(texts, embeddings, path=\"/content/drive/MyDrive/CyberCup23H2/qdrant_db\", collection_name=\"water\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Q4E6PqO46KGI"
      },
      "outputs": [],
      "source": [
        "# @title Init LLM\n",
        "\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "# Make sure the model path is correct for your system!\n",
        "llm = OpenAI()\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), memory=memory)\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(\n",
        "  llm=llm,\n",
        "  retriever=vectorstore.as_retriever(search_kwargs={'k': 2}),\n",
        "  memory=memory,\n",
        "  # return_source_documents=True,\n",
        "  max_tokens_limit=1024\n",
        ")\n",
        "\n",
        "# qa = ConversationalRetrievalChain(\n",
        "#   retriever=vectorstore.as_retriever(search_kwargs={'k': 2}),\n",
        "#   question_generator=question_generator,\n",
        "#   combine_docs_chain=doc_chain,\n",
        "#   memory=memory,\n",
        "#   max_tokens_limit=512,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yllaqLFD7YEd"
      },
      "outputs": [],
      "source": [
        "# @title Ask\n",
        "\n",
        "query = \"how many lakes in india\" # @param {type:\"string\"}\n",
        "result = qa({\"question\": query})\n",
        "\n",
        "print(result)\n",
        "print(result['question'])\n",
        "print(result['answer'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cPoTGsJXY3r8"
      },
      "outputs": [],
      "source": [
        "# @title Setup Flask Server\n",
        "from flask import Flask, request\n",
        "\n",
        "from flask_ngrok2 import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app=app, auth_token='')\n",
        "\n",
        "@app.route('/', methods=['POST', 'GET'])\n",
        "def hello_world():\n",
        "  print(request)\n",
        "  print(request.form)\n",
        "  print(request.method)\n",
        "\n",
        "  result = qa({\"question\": request.form[\"query\"]})\n",
        "\n",
        "  return result[\"answer\"]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "98c6__ipae4O"
      },
      "outputs": [],
      "source": [
        "# @title Run API Server\n",
        "os.environ[\"FLASK_DEBUG\"] = \"False\"\n",
        "app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0K28paCSpSbY"
      },
      "outputs": [],
      "source": [
        "# @markdown gg\n",
        "break\n",
        "!pip install Flask --upgrade\n",
        "!pip install flask-ngrok2 --upgrade\n",
        "\n",
        "from flask import Flask, request\n",
        "\n",
        "from flask_ngrok2 import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app=app, auth_token='1gNClmywUFSKSEG0WscPkJiG6eE_282GBBTd5PuNEqauXo9hj')\n",
        "\n",
        "@app.route('/', methods=['POST', 'GET'])\n",
        "def hello_world():\n",
        "  print(request)\n",
        "  print(request.form)\n",
        "  print(request.method)\n",
        "\n",
        "  return \"hallo\"\n",
        "\n",
        "os.environ[\"FLASK_DEBUG\"] = \"False\"\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
